<!DOCTYPE html>
<html>
  <head>
    <title>An .red[Incomplete] Introduction to R</title>
    <meta charset="utf-8">
    <meta name="author" content="Brad Boehmke" />
    <meta name="date" content="2018-12-13" />
    <link href="libs/font-awesome-animation/font-awesome-animation-emi.css" rel="stylesheet" />
    <script src="libs/fontawesome/js/fontawesome-all.min.js"></script>
    <link rel="stylesheet" href="scrollable.css" type="text/css" />
    <link rel="stylesheet" href="mtheme_max.css" type="text/css" />
    <link rel="stylesheet" href="fonts_mtheme_max.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">




class: title-slide   
&lt;a href="https://github.8451.com/b294776/"&gt;&lt;img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"&gt;&lt;/a&gt;


&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
# An .red[Incomplete] Introduction to <span>&lt;i class="fab  fa-r-project faa-pulse animated faa-slow " style=" color:steelblue;"&gt;&lt;/i&gt;</span>

## .font70[.italic['Success is stumbling from failure to failure with no loss of enthusiasm'] - Winston Churchill]

### Brad Boehmke
### Dec 13-14, 2018

### Slides: TBD
### Script: TBD
### Data: TBD

---

class: clear, center, middle


background-image: url(images/introductions.jpg)
background-size: cover

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

.pull-left-narrow[
.font200.white[Introductions]
]
---

# About me

.pull-left[

&lt;img src="images/name-tag.png" width="1360" style="display: block; margin: auto;" /&gt;

* [&lt;svg style="height:0.8em;top:.04em;position:relative;fill:steelblue;" viewBox="0 0 496 512"&gt;&lt;path d="M336.5 160C322 70.7 287.8 8 248 8s-74 62.7-88.5 152h177zM152 256c0 22.2 1.2 43.5 3.3 64h185.3c2.1-20.5 3.3-41.8 3.3-64s-1.2-43.5-3.3-64H155.3c-2.1 20.5-3.3 41.8-3.3 64zm324.7-96c-28.6-67.9-86.5-120.4-158-141.6 24.4 33.8 41.2 84.7 50 141.6h108zM177.2 18.4C105.8 39.6 47.8 92.1 19.3 160h108c8.7-56.9 25.5-107.8 49.9-141.6zM487.4 192H372.7c2.1 21 3.3 42.5 3.3 64s-1.2 43-3.3 64h114.6c5.5-20.5 8.6-41.8 8.6-64s-3.1-43.5-8.5-64zM120 256c0-21.5 1.2-43 3.3-64H8.6C3.2 212.5 0 233.8 0 256s3.2 43.5 8.6 64h114.6c-2-21-3.2-42.5-3.2-64zm39.5 96c14.5 89.3 48.7 152 88.5 152s74-62.7 88.5-152h-177zm159.3 141.6c71.4-21.2 129.4-73.7 158-141.6h-108c-8.8 56.9-25.6 107.8-50 141.6zM19.3 352c28.6 67.9 86.5 120.4 158 141.6-24.4-33.8-41.2-84.7-50-141.6h-108z"/&gt;&lt;/svg&gt;](http://bradleyboehmke.github.io/) bradleyboehmke.github.io
* [&lt;svg style="height:0.8em;top:.04em;position:relative;fill:steelblue;" viewBox="0 0 496 512"&gt;&lt;path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/&gt;&lt;/svg&gt;](https://github.com/bradleyboehmke/) @bradleyboehmke
* [&lt;svg style="height:0.8em;top:.04em;position:relative;fill:steelblue;" viewBox="0 0 512 512"&gt;&lt;path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/&gt;&lt;/svg&gt;](https://twitter.com/bradleyboehmke) @bradleyboehmke
* [&lt;svg style="height:0.8em;top:.04em;position:relative;fill:steelblue;" viewBox="0 0 448 512"&gt;&lt;path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/&gt;&lt;/svg&gt;](https://www.linkedin.com/in/brad-boehmke-ph-d-9b0a257/) @bradleyboehmke
* [&lt;svg style="height:0.8em;top:.04em;position:relative;fill:steelblue;" viewBox="0 0 512 512"&gt;&lt;path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/&gt;&lt;/svg&gt;](mailto:bradleyboehmke@gmail.com) bradleyboehmke@gmail.com

]


.pull-right[

#### Family &lt;img src="images/family.png" align="right" alt="family" width="130" /&gt;

* Dayton, OH
* Kate, Alivia (9), Jules (6)


#### Professional 

* 84.51Â° - Data Science Enabler &lt;img src="images/logo8451.jpg" align="right" alt="family" width="150" /&gt;

#### Academic

* University of Cincinnati &lt;img src="images/uc.png" align="right" alt="family" width="100" /&gt;
* Air Force Institute of Technology

#### R Community

&lt;img src="images/r-contributions.png" alt="family" width="400" /&gt;

]

---

# Data science

&lt;img src="images/data-science.png" width="60%" style="display: block; margin: auto;" /&gt;

---

# Data science

&lt;img src="images/data-science-2.png" width="80%" style="display: block; margin: auto;" /&gt;

---

# Data science

&lt;img src="images/applied-data-science.gif" width="95%" style="display: block; margin: auto;" /&gt;

---

# Course objectives!

&lt;br&gt;

.font150[Provide an intensive, hands-on introduction to the <span>&lt;i class="fab  fa-r-project faa-FALSE animated " style=" color:steelblue;"&gt;&lt;/i&gt;</span> programming language:]

.pull-left[

.center[.bold[.font120[Day 1]]]
 
| Topic | Time |
|:------|------|
| Fundamentals | 9:00 - 10:00 |
| Importing data | 10:00 - 10:30 |
| Break | 10:30 - 10:45 |
| Data transformation | 10:45 - 12:00 |
| Lunch | 12:00 - 1:00 |
| Data visualization | xx-xx |

]

.pull-right[

.center[.bold[.font120[Day 2]]]
 
| Topic | Time |
|:------|------|
| Tidying data | xx-xx |
| Joining data | xx-xx |
| Data structures | xx-xx |
| Exploratory data analysis | xx-xx |

]

---

# A hands-on learning environment

.pull-left[

### You may be overwhelmed

&lt;img src="images/drowning.gif" height="400" style="display: block; margin: auto;" /&gt;

]

--

.pull-right[

### So work together

&lt;img src="images/dogs-helping.gif" height="400" style="display: block; margin: auto;" /&gt;

]

---

# Class material

&lt;a href="https://github.8451.com/b294776/analytics-connect-intro-r" class="github-corner" aria-label="View source on Github"&gt;&lt;svg width="80" height="80" viewBox="0 0 250 250" style="fill:#fff; color:#151513; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"&gt;&lt;path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"&gt;&lt;/path&gt;&lt;path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"&gt;&lt;/path&gt;&lt;path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;style&gt;.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}&lt;/style&gt;

.pull-left[

### Source code 

- <span>&lt;i class="fab  fa-slideshare faa-pulse animated-hover "&gt;&lt;/i&gt; Slides</span>: TBD

- <span>&lt;i class="fas  fa-code faa-pulse animated-hover "&gt;&lt;/i&gt; Student Script</span>: TBD

- <span>&lt;i class="fas  fa-database faa-pulse animated-hover "&gt;&lt;/i&gt; Data</span>: TBD

- <span>&lt;i class="fab  fa-github faa-pulse animated-hover "&gt;&lt;/i&gt; GitHub</span>: TBD

]

--

.pull-right[

### UC R Programming Guide 

- http://uc-r.github.io

&lt;img src="images/uc-guide.png" width="500" style="display: block; margin: auto;" /&gt;

]

---
class: yourturn
# Your Turn!

&lt;br&gt;
## .font150[Meet your neighbors:]

.font140[
1. What is their experience with R?
2. What programming experience other than R do they have?
2. How are they using, or how do they plan to use, R in their job?
]



---

class: clear, center, middle


background-image: url(images/prereqs.jpg)
background-size: cover

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

.pull-left-narrow[
.font200[Prerequisites]
]

---

# Software

.pull-left[

### R (programming language) &lt;svg style="height:0.8em;top:.04em;position:relative;fill:steelblue;" viewBox="0 0 581 512"&gt;&lt;path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"/&gt;&lt;/svg&gt;

1. Go to https://cran.r-project.org/
2. Click "Download R for Mac/Windows"
3. Download the appropriate file:
   - Windows users click Base, and download the installer for the latest R version
   - Mac users select the file R-3.X.X that aligns with your OS version
4. Follow the instructions of the installer   

]

.pull-right[

### RStudio (IDE) &lt;img src="https://dfsuknfbz46oq.cloudfront.net/p/icons/rstudio.png" width="35" align="center"/&gt;

1. Go to RStudio for desktop https://www.rstudio.com/products/rstudio/download/#download
2. Select the install file for your OS
3. Follow the instructions of the installer  

]

&lt;br&gt;
&lt;br&gt;

.center[
.content-box-gray[.bold[You should have R version 3.4.5 or greater installed.]]
]


---

# Questions about the class

&lt;br&gt;

&lt;img src="images/questions.png" width="450" height="450" style="display: block; margin: auto;" /&gt;

---

class: clear, center, middle


background-image: url(images/fundamentals.png)
background-size: cover

---

# Understanding the RStudio IDE

&lt;img src="images/RStudio-console.png" width="2299" style="display: block; margin: auto;" /&gt;

.center[Learn more IDE features: `Help &gt;&gt; Cheatsheets &gt;&gt; RStudio IDE Cheat Sheet`]

---
class: yourturn
# Your Turn!

&lt;br&gt;&lt;br&gt;
.font130[
(1). Open .R script for this class (`intro-r-student-script.R`)
]
.pull-left[
.font130[
(2) Write and execute the following code in the .R script and identify where in the IDE the outputs can be found:
]]

.pull-right[


```r
mtcars
?sum
hist(mtcars$mpg)
random_numbers &lt;- runif(25)
history()
```
]

&lt;br&gt;

.center[.content-box-gray[.bold[Run the code with `cmd + enter` or selecting run button &lt;img src="images/run-button.png" align="center"/&gt;.]]]

---

# Getting help

.pull-left[

### In general

* __Google__: just add "with R" at the end of any search
* __Stack Overflow__: focused on programming questions
* __Cross Validated__: focused on statistical questions

### FOMO

* __R-bloggers__: blog aggregator
* __Twitter__: #rstats

]

.pull-right[

### Within R


```r
# provides details for specific function
help(sqrt)
*?sqrt

# provides examples for said function
example(sqrt)
```


]

---

# Setting your working directory

.font130[.bold[Keeping your files <span>&lt;i class="fas  fa-copy faa-pulse animated-hover faa-slow "&gt;&lt;/i&gt;</span> organized is critical!]]

.pull-left[

```r
# get your current working directory
getwd()
## [1] "/Users/b294776/Desktop/Training"

# set your working directory
setwd("/Users/b294776/Desktop/Training/intro-r")

getwd()
## [1] "/Users/b294776/Desktop/Training/intro-r"
```

]

.pull-right[

&lt;img src="images/set-wk-dir.png" width="1072" style="display: block; margin: auto;" /&gt;

]

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
.center[.bold[.content-box-gray[.red[Set your working directory to the location you want to work in for this training.]]]]

---

# Some basics

.pull-left[

### R as a calculator <span>&lt;i class="fas  fa-calculator faa-pulse animated-hover faa-slow "&gt;&lt;/i&gt;</span>


```r
# uses PEMBDAS convention for order of operations
4 + 3 / 10 ^ 2
## [1] 4.03
(4 + 3) / 10 ^ 2
## [1] 0.07
(4 + 3 / 10) ^ 2
## [1] 18.49

# calculations with NA produces NA
4 + 3 / 10 ^ NA 
## [1] NA
```

]

--

.pull-right[

### Assigning &amp; evaluating


```r
x &lt;- 4 + 3 / 10 ^ 2   # GOOD
x = 4 + 3 / 10 ^ 2    # BAD

# we can increment (build onto) existing objects
x
## [1] 4.03
x &lt;- x + 1
x
## [1] 5.03

# evaluation is case sensitive
X
## Error in eval(expr, envir, enclos): object 'X' not found
```


]

---

class: yourturn

# Your Turn!

.pull-left[

### Economic Order Quantity Model

`$$Q = \sqrt{\frac{2DK}{h}}$$`

Calculate *Q* where:

* `\(D=1000\)`
* `\(K=5\)`
* `\(h=0.25\)`

Save the result to an object called *Q*.

]

--

.pull-right[

### Solution


```r
D &lt;- 1000
K &lt;- 5
h &lt;- .25

Q &lt;- sqrt(2 * D * K / h)
Q
## [1] 200
```


]

---

# Workspace environment

.pull-left[
* You should now have 4 objects in your global environment
* History tab will show your recent code
* To list and remove these objects from your globa environment:


```r
# list all objects
ls()
## [1] "D" "h" "K" "Q"

# remove a single object
rm(D)

# remove all objects
rm(list = ls())
```

]

.pull-right[

&lt;img src="images/workspace.png" width="1365" style="display: block; margin: auto;" /&gt;


]

---

# Packages ð¦

The fundamental unit of shareable code is the .bold[package].

* CRAN: 13,000+
* Bioconductor: 1,500+
* GitHub: Many more plus beta versions for updated packages not yet published

&lt;img src="images/base-r-pkgs.png" width="60%" style="display: block; margin: auto;" /&gt;


---

# Packages ð¦

The fundamental unit of shareable code is the .bold[package].

* CRAN: 13,000+
* Bioconductor: 1,500+
* GitHub: Many more plus beta versions for updated packages not yet published

.blue[So how do we install these packages?]


```r
# install packages from CRAN
*install.packages("packagename")

# install packages from GitHub
install.packages("devtools")                            # only required the first time
devtools::install_github("username/packagename")
```

---

# Packages ð¦


.pull-left[

### Downloads files to computer


```r
install.packages("packagename")
```

.center[.content-box-gray[.bold[1x per computer]]]

]

.pull-right[

### Loads package to use


```r
library(packagename)
```

.center[.content-box-gray[.bold[1x per R session]]]

]

---

class: yourturn

# Your Turn!

.pull-left[

1. Download these packages from CRAN:
   * tidyverse
   * nycflights
   
2. Load both packages to use in your current R session   

]

--

.pull-right[
.bold[.font120[Solution:]]


```r
# install packages
install.packages("tidyverse")
install.packages("nycflights13")


# alternative
install.packages(c("tidyverse", "nycflights13"))

# load packages to use
library(tidyverse)
library(nycflights13)
```


]

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
.center[.content-box-gray[For a full list of useful packages see this guide:  http://bit.ly/1x9vkzV]]

---

# What is tidyverse?

.pull-left[

.bold[A collection of packages...]

&lt;img src="images/tidyverse.png" width="1365" style="display: block; margin: auto;" /&gt;

]

.pull-right[

.bold[designed to simplify data analysis]

&lt;br&gt;

&lt;img src="images/tidyverse-process.png" width="2543" style="display: block; margin: auto;" /&gt;

]

---

# What is tidyverse?

.scrollable90[
.pull-left[


```r
install.packages("tidyverse")
```


.bold[does the equivalent of...]


```r
install.packages("ggplot2")
install.packages("tibble")
install.packages("tidyr")
install.packages("readr")
install.packages("purrr")
install.packages("dplyr")
install.packages("stringr")
install.packages("forcats")
install.packages("hms")
install.packages("lubridate")
install.packages("DBI")
install.packages("haven")
install.packages("httr")
install.packages("jsonlite")
install.packages("readxl")
install.packages("rvest")
install.packages("xml2")
install.packages("modelr")
install.packages("broom")
```

]
]

---

# What is tidyverse?

.scrollable90[
.pull-left[


```r
install.packages("tidyverse")
```


.bold[does the equivalent of...]


```r
*install.packages("ggplot2")
*install.packages("tibble")
*install.packages("tidyr")
*install.packages("readr")
*install.packages("purrr")
*install.packages("dplyr")
*install.packages("stringr")
*install.packages("forcats")
install.packages("hms")
install.packages("lubridate")
install.packages("DBI")
install.packages("haven")
install.packages("httr")
install.packages("jsonlite")
install.packages("readxl")
install.packages("rvest")
install.packages("xml2")
install.packages("modelr")
install.packages("broom")
```

]

.pull-right[


```r
library(tidyverse)
```

.bold[does the equivalent of...]



```r
library(ggplot2) 
library(tibble) 
library(tidyr) 
library(readr) 
library(purrr) 
library(dplyr) 
library(stringr) 
library(forcats) 
```

]

]

---

# Questions before moving on?

&lt;br&gt;

&lt;img src="images/questions.png" width="450" height="450" style="display: block; margin: auto;" /&gt;

---

class: clear, center, middle


background-image: url(https://www.golegal.co.za/wp-content/uploads/2017/06/parallel-imports.jpg)
background-size: cover

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

.font200.white[Importing Data]

---

# First task in applied data science

&lt;br&gt;&lt;br&gt;
&lt;img src="images/importing-task.jpeg" style="display: block; margin: auto;" /&gt;

---

# Importing packages ð¦

&lt;img src="images/importing-pkgs.png" width="90%" style="display: block; margin: auto;" /&gt;

---

# readr for delimited files (i.e. .csv, .tsv. txt)


```r
# load readr library (or tidyverse)
library(readr)

# import data
products &lt;- read_csv(file = "data/products.csv")
products
## # A tibble: 151,141 x 5
##    product_num department commodity brand_ty x5   
##    &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;
##  1 0092993     NON-FOOD   PET       PRIVATE  N    
##  2 0093924     NON-FOOD   PET       PRIVATE  N    
##  3 0094272     NON-FOOD   PET       PRIVATE  N    
##  4 0094299     NON-FOOD   PET       PRIVATE  N    
##  5 0094594     NON-FOOD   PET       PRIVATE  N    
##  6 0094606     NON-FOOD   PET       PRIVATE  N    
##  7 0094613     NON-FOOD   PET       PRIVATE  N    
##  8 0095625     NON-FOOD   PET       PRIVATE  N    
##  9 0096152     NON-FOOD   PET       PRIVATE  N    
## 10 0096153     NON-FOOD   PET       PRIVATE  N    
## # ... with 151,131 more rows
```

.center[.content-box-gray[.bold[The products data has 151,141 observations (rows) and 5 features (columns)]]]

---

# readxl for Excel files

.pull-left-60[


```r
# load readr library (or tidyverse)
library(readxl)

# read workbook sheets
excel_sheets(path = "data/products.xlsx")
## [1] "metadata"     "products"     "grocery list"
```
]

.pull-right-40[


- First, we read in the worksheet names with .red[`excel_sheets()`] so we know which sheet to import

- .white[Then we read in the worksheet with `read_excel()`]
 
]

---

# readxl for Excel files

.pull-left-60[


```r
# load readr library (or tidyverse)
library(readxl)

# read workbook sheets
excel_sheets(path = "data/products.xlsx")
## [1] "metadata"      "products data" "grocery list"

# import sheet of interest
products &lt;- read_excel(path = "data/products.xlsx", sheet = "products data")
products
## # A tibble: 151,141 x 5
##    product_num department commodity brand_ty x5   
##          &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;
##  1       92993 NON-FOOD   PET       PRIVATE  N    
##  2       93924 NON-FOOD   PET       PRIVATE  N    
##  3       94272 NON-FOOD   PET       PRIVATE  N    
##  4       94299 NON-FOOD   PET       PRIVATE  N    
##  5       94594 NON-FOOD   PET       PRIVATE  N    
##  6       94606 NON-FOOD   PET       PRIVATE  N    
##  7       94613 NON-FOOD   PET       PRIVATE  N    
##  8       95625 NON-FOOD   PET       PRIVATE  N    
##  9       96152 NON-FOOD   PET       PRIVATE  N    
## 10       96153 NON-FOOD   PET       PRIVATE  N    
## # ... with 151,131 more rows
```

]

.pull-right-40[

- .gray[.opacity[First, we read in the worksheet names with `excel_sheets()` so we know which sheet to import]]
 
- Then we read in the worksheet with .red[`read_excel()`]

]

---

# Additional arguments

.font120[Both readr &amp; readxl have many arguments that allow you to...]

.pull-left[

### readr

* read .tsv, .txt, .fwf, and other flat files
* change column names
* change data types
* skip lines
* re-label missing values
]

.pull-right[

### readxl

* read a specified range from the spreadsheet
* change column names
* change data types
* skip lines
* re-label missing values

]

&lt;br&gt;&lt;br&gt;

.center[.content-box-gray[.bold[But these are more advanced options you can learn on your own]]]

---

# What if we have a .bold[<span class=" faa-pulse animated " style=" color:red; display: -moz-inline-stack; display: inline-block; transform: rotate(0deg);">big</span>] file?

.pull-left-40[

### Actual data set at work

* 840,861 observations
* 723 variables
* equates to 607,942,503 elements
* 2.7 GB

]

--

.pull-right-60[

### data.table::fread to the rescue <span style=" display: -moz-inline-stack; display: inline-block; transform: rotate(0deg);">&lt;img src="https://emojis.slackmojis.com/emojis/images/1471045870/910/rock.gif?1471045870" style="height:1em; width:auto; "/&gt;</span>


```r
# time to import with base R (27 minutes)
system.time(ynb1 &lt;- read.csv("data/ynb_cheese.csv"))
##    user  system elapsed 
## 317.349 1159.192 1678.552

# time to import with readr (10 minutes)
system.time(ynb2 &lt;- readr::read_csv("data/ynb_cheese.csv"))
##    user   system  elapsed 
## 500.954  71.776 594.505

# time to import with data.table::fread (1 minute)
*system.time(ynb3 &lt;- data.table::fread("data/ynb_cheese.csv", data.table = FALSE))
*##   user  system elapsed
*## 40.174   9.861  64.625

```


]



---
class: yourturn

# Your Turn!

Read in the __transactions.csv__ file and save as `transactions`

--

### Solution


```r
transactions &lt;- data.table::fread("data/transactions.csv", data.table = FALSE)
transactions
##         basket_num hshd_num purchase_ product_num  spend units store_r
## 1           100369     3708 09-DEC-17       93466   3.18     2   SOUTH
## 2           891779      719 20-SEP-17       85201   3.49     1 CENTRAL
## 3           609562     4995 07-MAR-17     2507006   0.89     1 CENTRAL
## 4           760220       44 19-JUN-17     4819172   8.99     1   SOUTH
## 5           869525     3937 04-SEP-17     1055355   1.00     1   SOUTH
## 6           922989     2356 13-OCT-17     4285485   2.87     1    WEST
## 7           732544      694 31-MAY-17        8511   0.64     1 CENTRAL
## 8           536185     3728 14-JAN-17       85939   1.00     1   SOUTH
## 9           967914      887 15-NOV-17     3775301   4.69     1 CENTRAL
## 10          102995      574 27-DEC-17       72765   1.29     1    EAST
## 11          948493     4646 31-OCT-17     5941722   4.39     1 CENTRAL
## 12          543967     1857 19-JAN-17     5322220   4.54     1    EAST
## 13          632790     2901 23-MAR-17     4010421   8.97     3    WEST
## 14          632276     3875 22-MAR-17      274694   2.89     1   SOUTH
## 15          761527     4862 21-JUN-17        8532   4.99     1    EAST
## 16          557571     1850 29-JAN-17     4700204   1.99     1 CENTRAL
## 17          544589     3754 20-JAN-17      208860   1.99     1    EAST
## 18          686032     4431 29-APR-17     6261179   4.00     2 CENTRAL
## 19          521430      337 03-JAN-17     5817464   2.25     1    EAST
## 20          518339     2471 01-JAN-17      256239   5.39     1 CENTRAL
## 21          938012     1432 22-OCT-17     4633778   0.99     1   SOUTH
## 22          574340     3290 09-FEB-17        8716   2.50     2    WEST
## 23          101918     3853 20-DEC-17     6176558   5.99     1   SOUTH
## 24          948817     4586 01-NOV-17      126122   1.67     1    EAST
## 25          722802     4731 25-MAY-17     4364736   6.99     1    WEST
## 26          539956     3600 14-JAN-17       77000   2.29     1   SOUTH
## 27          839259     4054 12-AUG-17     6151924   2.50     1   SOUTH
## 28          683839     2349 27-APR-17     5554873   3.99     1   SOUTH
## 29          916652     3356 08-OCT-17       98432   1.00     1   SOUTH
## 30          678068     2770 24-APR-17      383285   1.89     1    WEST
## 31          714526     1266 18-MAY-17      792861   4.99     1    EAST
## 32          723944     3718 24-MAY-17      193624   1.00     1   SOUTH
## 33          744115      319 07-JUN-17     3759090   1.00     1    EAST
## 34          925400     1251 14-OCT-17      100321   2.50     1    EAST
## 35          558376     1318 30-JAN-17     1148446  19.99     1    EAST
## 36          916776     3205 08-OCT-17     6031005   2.00     2 CENTRAL
## 37          715530     1716 20-MAY-17      667140   3.49     1    WEST
## 38          850838     1044 21-AUG-17      553634   3.99     1   SOUTH
## 39          899382     1288 25-SEP-17      494672   3.98     2    EAST
## 40          993603     1207 30-NOV-17      516365  10.58     2    EAST
## 41          528540     4484 09-JAN-17       85888   1.99     1   SOUTH
## 42          628627     2717 21-MAR-17     5319971   2.50     1    WEST
## 43          997628     3113 05-DEC-17      894199   4.49     1    EAST
## 44          801411     3451 19-JUL-17       84667   7.99     1   SOUTH
## 45          998420     1239 04-DEC-17        8564   1.18     2 CENTRAL
## 46          837440     1363 11-AUG-17      471144   3.29     1    EAST
## 47          622685     4677 15-MAR-17        8511   0.82     1   SOUTH
## 48          964126     2387 11-NOV-17     2690446  27.99     1    WEST
## 49          686663     1602 30-APR-17     4643198   1.99     1    WEST
## 50          845333     1617 18-AUG-17     1471041   1.67     1    WEST
## 51          646242     4471 01-APR-17      101602   1.50     1   SOUTH
## 52          579719     2951 12-FEB-17       85351   1.49     1    WEST
## 53          693738     2132 04-MAY-17     4768382   6.99     1   SOUTH
## 54          712325      558 15-MAY-17      340916   2.00     1    EAST
## 55          824031      193 03-AUG-17     5976866   2.39     1    EAST
## 56          821924      117 02-AUG-17        8655   0.58     1    EAST
## 57          582157     4664 14-FEB-17      926049   5.24     1   SOUTH
## 58          524577     2973 07-JAN-17      102176   1.49     1    WEST
## 59          570805     4267 08-FEB-17       85354   1.99     1    WEST
## 60          997008     4368 03-DEC-17      139549   1.99     1    EAST
## 61          931928     4459 20-OCT-17     5135955   2.00     1 CENTRAL
## 62          980534      201 20-NOV-17     5115496   7.89     1 CENTRAL
## 63          622068     1521 14-MAR-17     6115724   1.77     1    WEST
## 64          588480     1339 19-FEB-17     5373603   1.00     1    EAST
## 65          828313     3955 05-AUG-17     2179750   7.98     2    EAST
## 66          650913     3706 04-APR-17       99994   1.00     1   SOUTH
## 67          819096     4650 31-JUL-17       86939   2.50     1    WEST
## 68          862538     1295 30-AUG-17     2186456   2.99     1    EAST
## 69          714452     2143 18-MAY-17      899148   3.39     1    EAST
## 70          754851      851 16-JUN-17       94608   1.38     2 CENTRAL
## 71          885323     1676 16-SEP-17      966252   2.99     1    EAST
## 72          763834     1535 21-JUN-17       89360   1.89     1    WEST
## 73          611155     1998 07-MAR-17     3834271   3.49     1    EAST
## 74          943237     1337 26-OCT-17      100642   1.99     1   SOUTH
## 75          922342     4234 11-OCT-17     4754169   6.99     1    EAST
## 76          524581      760 07-JAN-17     5682276   0.99     1 CENTRAL
## 77          700300      689 08-MAY-17      142441   3.19     1 CENTRAL
## 78          102310     2098 23-DEC-17     4634392   3.88     1    WEST
## 79          586198     4873 17-FEB-17     6115591   1.99     1   SOUTH
## 80          993710     4427 01-DEC-17      403814   1.00     1   SOUTH
## 81          581242     3998 13-FEB-17     6330732   2.00     2   SOUTH
## 82          645429     3404 01-APR-17        8511   1.33     1   SOUTH
## 83          677886     3975 23-APR-17        8511   0.90     1 CENTRAL
## 84          628825     3470 21-MAR-17     5504753   8.99     1   SOUTH
## 85          868499     3884 04-SEP-17     1096402   1.79     1 CENTRAL
## 86          762886     1009 20-JUN-17       90023   1.39     1 CENTRAL
## 87          652679     3501 06-APR-17     5819719   2.79     1   SOUTH
## 88          926570       91 15-OCT-17     5322222   4.76     1 CENTRAL
## 89          718053        7 22-MAY-17      279126   3.69     1    EAST
## 90          798967     1498 15-JUL-17       68594   0.99     1    EAST
## 91          704762     3865 13-MAY-17        9036   0.63     1    EAST
## 92          609206     1847 05-MAR-17     1428710  13.49     1    EAST
## 93          844254     1944 16-AUG-17     6364885   1.00     1 CENTRAL
## 94          561585     2061 31-JAN-17     5249973   3.49     1    EAST
## 95          865262     4140 30-AUG-17      102929   0.99     1 CENTRAL
## 96          815027     3293 28-JUL-17     6495492   0.29     1   SOUTH
## 97          609551      261 06-MAR-17      714496   4.00     4    EAST
## 98          103016     2367 27-DEC-17      962407   3.34     1 CENTRAL
## 99          521124      314 02-JAN-17       96932   2.00     2    EAST
## 100         979411     3756 21-NOV-17       93547   6.29     1 CENTRAL
## 101         573688     4960 09-FEB-17     6403056   0.89     1    WEST
## 102         816885     2430 29-JUL-17     5632506   6.49     1    EAST
## 103         565558     4939 02-FEB-17     6176562   5.98     2    WEST
## 104         674865     4979 21-APR-17      102965   0.99     1    EAST
## 105         577981     4635 11-FEB-17      765613   1.79     1    WEST
## 106         791334     1824 10-JUL-17       93688   3.99     1 CENTRAL
## 107         967421      322 13-NOV-17     1343782   5.50     1    EAST
## 108         671221      622 18-APR-17       90777   3.00     5 CENTRAL
## 109         781219      729 03-JUL-17      100701   1.79     1 CENTRAL
## 110         542044     1571 18-JAN-17      101499   1.00     1 CENTRAL
## 111         720471      952 21-MAY-17       86626   2.25     1 CENTRAL
##         week_num year
## 1            101 2017
## 2             90 2017
## 3             62 2017
## 4             77 2017
## 5             88 2017
## 6             93 2017
## 7             74 2017
## 8             54 2017
## 9             98 2017
## 10           104 2017
## 11            96 2017
## 12            55 2017
## 13            64 2017
## 14            64 2017
## 15            77 2017
## 16            57 2017
## 17            55 2017
## 18            69 2017
## 19            53 2017
## 20            53 2017
## 21            95 2017
## 22            58 2017
## 23           103 2017
## 24            96 2017
## 25            73 2017
## 26            54 2017
## 27            84 2017
## 28            69 2017
## 29            93 2017
## 30            69 2017
## 31            72 2017
## 32            73 2017
## 33            75 2017
## 34            93 2017
## 35            57 2017
## 36            93 2017
## 37            72 2017
## 38            86 2017
## 39            91 2017
## 40           100 2017
## 41            54 2017
## 42            64 2017
## 43           101 2017
## 44            81 2017
## 45           101 2017
## 46            84 2017
## 47            63 2017
## 48            97 2017
## 49            70 2017
## 50            85 2017
## 51            65 2017
## 52            59 2017
## 53            70 2017
## 54            72 2017
## 55            83 2017
## 56            83 2017
## 57            59 2017
## 58            53 2017
## 59            58 2017
## 60           101 2017
## 61            94 2017
## 62            99 2017
## 63            63 2017
## 64            60 2017
## 65            83 2017
## 66            66 2017
## 67            83 2017
## 68            87 2017
## 69            72 2017
## 70            76 2017
## 71            89 2017
## 72            77 2017
## 73            62 2017
## 74            95 2017
## 75            93 2017
## 76            53 2017
## 77            71 2017
## 78           103 2017
## 79            59 2017
## 80           100 2017
## 81            59 2017
## 82            65 2017
## 83            69 2017
## 84            64 2017
## 85            88 2017
## 86            77 2017
## 87            66 2017
## 88            94 2017
## 89            73 2017
## 90            80 2017
## 91            71 2017
## 92            62 2017
## 93            85 2017
## 94            57 2017
## 95            87 2017
## 96            82 2017
## 97            62 2017
## 98           104 2017
## 99            53 2017
## 100           99 2017
## 101           58 2017
## 102           82 2017
## 103           57 2017
## 104           68 2017
## 105           58 2017
## 106           80 2017
## 107           98 2017
## 108           68 2017
## 109           79 2017
## 110           55 2017
## 111           73 2017
##  [ reached getOption("max.print") -- omitted 1857456 rows ]
```

---

# Wait, that looks different...

&lt;img src="images/wait-one-sec.gif" width="70%" style="display: block; margin: auto;" /&gt;


---

# Tibbles

.scrollable90[
.pull-left[

### data frame 


```r
transactions &lt;- data.table::fread("data/transactions.csv", data.table = FALSE)
transactions
##         basket_num hshd_num purchase_ product_num  spend units store_r
## 1           100369     3708 09-DEC-17       93466   3.18     2   SOUTH
## 2           891779      719 20-SEP-17       85201   3.49     1 CENTRAL
## 3           609562     4995 07-MAR-17     2507006   0.89     1 CENTRAL
## 4           760220       44 19-JUN-17     4819172   8.99     1   SOUTH
## 5           869525     3937 04-SEP-17     1055355   1.00     1   SOUTH
## 6           922989     2356 13-OCT-17     4285485   2.87     1    WEST
## 7           732544      694 31-MAY-17        8511   0.64     1 CENTRAL
## 8           536185     3728 14-JAN-17       85939   1.00     1   SOUTH
## 9           967914      887 15-NOV-17     3775301   4.69     1 CENTRAL
## 10          102995      574 27-DEC-17       72765   1.29     1    EAST
## 11          948493     4646 31-OCT-17     5941722   4.39     1 CENTRAL
## 12          543967     1857 19-JAN-17     5322220   4.54     1    EAST
## 13          632790     2901 23-MAR-17     4010421   8.97     3    WEST
## 14          632276     3875 22-MAR-17      274694   2.89     1   SOUTH
## 15          761527     4862 21-JUN-17        8532   4.99     1    EAST
## 16          557571     1850 29-JAN-17     4700204   1.99     1 CENTRAL
## 17          544589     3754 20-JAN-17      208860   1.99     1    EAST
## 18          686032     4431 29-APR-17     6261179   4.00     2 CENTRAL
## 19          521430      337 03-JAN-17     5817464   2.25     1    EAST
## 20          518339     2471 01-JAN-17      256239   5.39     1 CENTRAL
## 21          938012     1432 22-OCT-17     4633778   0.99     1   SOUTH
## 22          574340     3290 09-FEB-17        8716   2.50     2    WEST
## 23          101918     3853 20-DEC-17     6176558   5.99     1   SOUTH
## 24          948817     4586 01-NOV-17      126122   1.67     1    EAST
## 25          722802     4731 25-MAY-17     4364736   6.99     1    WEST
## 26          539956     3600 14-JAN-17       77000   2.29     1   SOUTH
## 27          839259     4054 12-AUG-17     6151924   2.50     1   SOUTH
## 28          683839     2349 27-APR-17     5554873   3.99     1   SOUTH
## 29          916652     3356 08-OCT-17       98432   1.00     1   SOUTH
## 30          678068     2770 24-APR-17      383285   1.89     1    WEST
## 31          714526     1266 18-MAY-17      792861   4.99     1    EAST
## 32          723944     3718 24-MAY-17      193624   1.00     1   SOUTH
## 33          744115      319 07-JUN-17     3759090   1.00     1    EAST
## 34          925400     1251 14-OCT-17      100321   2.50     1    EAST
## 35          558376     1318 30-JAN-17     1148446  19.99     1    EAST
## 36          916776     3205 08-OCT-17     6031005   2.00     2 CENTRAL
## 37          715530     1716 20-MAY-17      667140   3.49     1    WEST
## 38          850838     1044 21-AUG-17      553634   3.99     1   SOUTH
## 39          899382     1288 25-SEP-17      494672   3.98     2    EAST
## 40          993603     1207 30-NOV-17      516365  10.58     2    EAST
## 41          528540     4484 09-JAN-17       85888   1.99     1   SOUTH
## 42          628627     2717 21-MAR-17     5319971   2.50     1    WEST
## 43          997628     3113 05-DEC-17      894199   4.49     1    EAST
## 44          801411     3451 19-JUL-17       84667   7.99     1   SOUTH
## 45          998420     1239 04-DEC-17        8564   1.18     2 CENTRAL
## 46          837440     1363 11-AUG-17      471144   3.29     1    EAST
## 47          622685     4677 15-MAR-17        8511   0.82     1   SOUTH
## 48          964126     2387 11-NOV-17     2690446  27.99     1    WEST
## 49          686663     1602 30-APR-17     4643198   1.99     1    WEST
## 50          845333     1617 18-AUG-17     1471041   1.67     1    WEST
## 51          646242     4471 01-APR-17      101602   1.50     1   SOUTH
## 52          579719     2951 12-FEB-17       85351   1.49     1    WEST
## 53          693738     2132 04-MAY-17     4768382   6.99     1   SOUTH
## 54          712325      558 15-MAY-17      340916   2.00     1    EAST
## 55          824031      193 03-AUG-17     5976866   2.39     1    EAST
## 56          821924      117 02-AUG-17        8655   0.58     1    EAST
## 57          582157     4664 14-FEB-17      926049   5.24     1   SOUTH
## 58          524577     2973 07-JAN-17      102176   1.49     1    WEST
## 59          570805     4267 08-FEB-17       85354   1.99     1    WEST
## 60          997008     4368 03-DEC-17      139549   1.99     1    EAST
## 61          931928     4459 20-OCT-17     5135955   2.00     1 CENTRAL
## 62          980534      201 20-NOV-17     5115496   7.89     1 CENTRAL
## 63          622068     1521 14-MAR-17     6115724   1.77     1    WEST
## 64          588480     1339 19-FEB-17     5373603   1.00     1    EAST
## 65          828313     3955 05-AUG-17     2179750   7.98     2    EAST
## 66          650913     3706 04-APR-17       99994   1.00     1   SOUTH
## 67          819096     4650 31-JUL-17       86939   2.50     1    WEST
## 68          862538     1295 30-AUG-17     2186456   2.99     1    EAST
## 69          714452     2143 18-MAY-17      899148   3.39     1    EAST
## 70          754851      851 16-JUN-17       94608   1.38     2 CENTRAL
## 71          885323     1676 16-SEP-17      966252   2.99     1    EAST
## 72          763834     1535 21-JUN-17       89360   1.89     1    WEST
## 73          611155     1998 07-MAR-17     3834271   3.49     1    EAST
## 74          943237     1337 26-OCT-17      100642   1.99     1   SOUTH
## 75          922342     4234 11-OCT-17     4754169   6.99     1    EAST
## 76          524581      760 07-JAN-17     5682276   0.99     1 CENTRAL
## 77          700300      689 08-MAY-17      142441   3.19     1 CENTRAL
## 78          102310     2098 23-DEC-17     4634392   3.88     1    WEST
## 79          586198     4873 17-FEB-17     6115591   1.99     1   SOUTH
## 80          993710     4427 01-DEC-17      403814   1.00     1   SOUTH
## 81          581242     3998 13-FEB-17     6330732   2.00     2   SOUTH
## 82          645429     3404 01-APR-17        8511   1.33     1   SOUTH
## 83          677886     3975 23-APR-17        8511   0.90     1 CENTRAL
## 84          628825     3470 21-MAR-17     5504753   8.99     1   SOUTH
## 85          868499     3884 04-SEP-17     1096402   1.79     1 CENTRAL
## 86          762886     1009 20-JUN-17       90023   1.39     1 CENTRAL
## 87          652679     3501 06-APR-17     5819719   2.79     1   SOUTH
## 88          926570       91 15-OCT-17     5322222   4.76     1 CENTRAL
## 89          718053        7 22-MAY-17      279126   3.69     1    EAST
## 90          798967     1498 15-JUL-17       68594   0.99     1    EAST
## 91          704762     3865 13-MAY-17        9036   0.63     1    EAST
## 92          609206     1847 05-MAR-17     1428710  13.49     1    EAST
## 93          844254     1944 16-AUG-17     6364885   1.00     1 CENTRAL
## 94          561585     2061 31-JAN-17     5249973   3.49     1    EAST
## 95          865262     4140 30-AUG-17      102929   0.99     1 CENTRAL
## 96          815027     3293 28-JUL-17     6495492   0.29     1   SOUTH
## 97          609551      261 06-MAR-17      714496   4.00     4    EAST
## 98          103016     2367 27-DEC-17      962407   3.34     1 CENTRAL
## 99          521124      314 02-JAN-17       96932   2.00     2    EAST
## 100         979411     3756 21-NOV-17       93547   6.29     1 CENTRAL
## 101         573688     4960 09-FEB-17     6403056   0.89     1    WEST
## 102         816885     2430 29-JUL-17     5632506   6.49     1    EAST
## 103         565558     4939 02-FEB-17     6176562   5.98     2    WEST
## 104         674865     4979 21-APR-17      102965   0.99     1    EAST
## 105         577981     4635 11-FEB-17      765613   1.79     1    WEST
## 106         791334     1824 10-JUL-17       93688   3.99     1 CENTRAL
## 107         967421      322 13-NOV-17     1343782   5.50     1    EAST
## 108         671221      622 18-APR-17       90777   3.00     5 CENTRAL
## 109         781219      729 03-JUL-17      100701   1.79     1 CENTRAL
## 110         542044     1571 18-JAN-17      101499   1.00     1 CENTRAL
## 111         720471      952 21-MAY-17       86626   2.25     1 CENTRAL
##         week_num year
## 1            101 2017
## 2             90 2017
## 3             62 2017
## 4             77 2017
## 5             88 2017
## 6             93 2017
## 7             74 2017
## 8             54 2017
## 9             98 2017
## 10           104 2017
## 11            96 2017
## 12            55 2017
## 13            64 2017
## 14            64 2017
## 15            77 2017
## 16            57 2017
## 17            55 2017
## 18            69 2017
## 19            53 2017
## 20            53 2017
## 21            95 2017
## 22            58 2017
## 23           103 2017
## 24            96 2017
## 25            73 2017
## 26            54 2017
## 27            84 2017
## 28            69 2017
## 29            93 2017
## 30            69 2017
## 31            72 2017
## 32            73 2017
## 33            75 2017
## 34            93 2017
## 35            57 2017
## 36            93 2017
## 37            72 2017
## 38            86 2017
## 39            91 2017
## 40           100 2017
## 41            54 2017
## 42            64 2017
## 43           101 2017
## 44            81 2017
## 45           101 2017
## 46            84 2017
## 47            63 2017
## 48            97 2017
## 49            70 2017
## 50            85 2017
## 51            65 2017
## 52            59 2017
## 53            70 2017
## 54            72 2017
## 55            83 2017
## 56            83 2017
## 57            59 2017
## 58            53 2017
## 59            58 2017
## 60           101 2017
## 61            94 2017
## 62            99 2017
## 63            63 2017
## 64            60 2017
## 65            83 2017
## 66            66 2017
## 67            83 2017
## 68            87 2017
## 69            72 2017
## 70            76 2017
## 71            89 2017
## 72            77 2017
## 73            62 2017
## 74            95 2017
## 75            93 2017
## 76            53 2017
## 77            71 2017
## 78           103 2017
## 79            59 2017
## 80           100 2017
## 81            59 2017
## 82            65 2017
## 83            69 2017
## 84            64 2017
## 85            88 2017
## 86            77 2017
## 87            66 2017
## 88            94 2017
## 89            73 2017
## 90            80 2017
## 91            71 2017
## 92            62 2017
## 93            85 2017
## 94            57 2017
## 95            87 2017
## 96            82 2017
## 97            62 2017
## 98           104 2017
## 99            53 2017
## 100           99 2017
## 101           58 2017
## 102           82 2017
## 103           57 2017
## 104           68 2017
## 105           58 2017
## 106           80 2017
## 107           98 2017
## 108           68 2017
## 109           79 2017
## 110           55 2017
## 111           73 2017
##  [ reached getOption("max.print") -- omitted 1857456 rows ]
```

]

.pull-right[

### tibble 


```r
transactions &lt;- read_csv("data/transactions.csv")
transactions
## # A tibble: 1,857,567 x 9
##    basket_num hshd_num purchase_ product_num spend units store_r week_num
##         &lt;int&gt;    &lt;int&gt; &lt;chr&gt;           &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;      &lt;int&gt;
##  1     100369     3708 09-DEC-17       93466  3.18     2 SOUTH        101
##  2     891779      719 20-SEP-17       85201  3.49     1 CENTRAL       90
##  3     609562     4995 07-MAR-17     2507006  0.89     1 CENTRAL       62
##  4     760220       44 19-JUN-17     4819172  8.99     1 SOUTH         77
##  5     869525     3937 04-SEP-17     1055355  1        1 SOUTH         88
##  6     922989     2356 13-OCT-17     4285485  2.87     1 WEST          93
##  7     732544      694 31-MAY-17        8511  0.64     1 CENTRAL       74
##  8     536185     3728 14-JAN-17       85939  1        1 SOUTH         54
##  9     967914      887 15-NOV-17     3775301  4.69     1 CENTRAL       98
## 10     102995      574 27-DEC-17       72765  1.29     1 EAST         104
## # ... with 1,857,557 more rows, and 1 more variable: year &lt;int&gt;
```

]
]

---

# Tibbles

.scrollable90[
.pull-left[

### data frame `\(\rightarrow\)` tibble 


```r
transactions &lt;- data.table::fread("data/transactions.csv", data.table = FALSE)
*transactions &lt;- as.tibble(transactions)

transactions
## # A tibble: 1,857,567 x 9
##    basket_num hshd_num purchase_ product_num spend units store_r week_num
##         &lt;int&gt;    &lt;int&gt; &lt;chr&gt;           &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;      &lt;int&gt;
##  1     100369     3708 09-DEC-17       93466  3.18     2 SOUTH        101
##  2     891779      719 20-SEP-17       85201  3.49     1 CENTRAL       90
##  3     609562     4995 07-MAR-17     2507006  0.89     1 CENTRAL       62
##  4     760220       44 19-JUN-17     4819172  8.99     1 SOUTH         77
##  5     869525     3937 04-SEP-17     1055355  1        1 SOUTH         88
##  6     922989     2356 13-OCT-17     4285485  2.87     1 WEST          93
##  7     732544      694 31-MAY-17        8511  0.64     1 CENTRAL       74
##  8     536185     3728 14-JAN-17       85939  1        1 SOUTH         54
##  9     967914      887 15-NOV-17     3775301  4.69     1 CENTRAL       98
## 10     102995      574 27-DEC-17       72765  1.29     1 EAST         104
## # ... with 1,857,557 more rows, and 1 more variable: year &lt;int&gt;
```

]

.pull-right[

&lt;br&gt;&lt;br&gt;&lt;br&gt;

&lt;img src="images/i-like.gif" style="display: block; margin: auto;" /&gt;

]
]

---

# Get to know your data

.font120[Try these functions on your __transactions__ data:]


```r
# dimensions (rows x columns)
dim(transactions)

# get a quick glimpse of the data
glimpse(transactions)

# get the names of all the variables
names(transactions)

# how many missing values exist
sum(is.na(transactions))

# omit all observations with missing values
clean_data &lt;- na.omit(transactions)

# view the data in a spreadsheet like viewer
View(transactions)
```

--
&lt;br&gt;
.center[.content-box-gray[.bold[.red[So we have our data, now what?]]]]

---
class: clear, center, middle

background-image: url(images/transformer.gif)
background-size: cover

.font200.white.bold[Transforming Data]

---

# dplyr

You are going to learn six key .bold[dplyr] functions that allow you to solve the vast majority of your data manipulation challenges:

.pull-left[

* .bold[`filter`]: pick observations based on values

* .bold[`select`]: pick variables

* .bold[`summarize`]: compute statistical summaries 

* .bold[`group_by`]: perform operations at different levels of your data

* .bold[`arrange`]: reorder data

* .bold[`mutate`]: create new variables

]

.pull-right[

&lt;br&gt;
&lt;img src="images/dplyr.png" width="50%" height="50%" style="display: block; margin: auto;" /&gt;
&lt;br&gt;
]

---

# Basics

.font130[All functions work similarly:]
.font120[
* The first argument is a data frame
* Subsequent arguments describe what to do
* Output is a new data frame
]

&lt;br&gt;

&lt;img src="images/function-in-out.png" width="1343" style="display: block; margin: auto;" /&gt;

---
# Prerequisites

.pull-left[

### Packages


```r
library(dplyr) # or library(tidyverse)
```


]

.pull-right[

### Data


```r
transactions
## # A tibble: 1,857,567 x 9
##    basket_num hshd_num purchase_ product_num spend units store_r week_num
##         &lt;int&gt;    &lt;int&gt; &lt;chr&gt;           &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;      &lt;int&gt;
##  1     100369     3708 09-DEC-17       93466  3.18     2 SOUTH        101
##  2     891779      719 20-SEP-17       85201  3.49     1 CENTRAL       90
##  3     609562     4995 07-MAR-17     2507006  0.89     1 CENTRAL       62
##  4     760220       44 19-JUN-17     4819172  8.99     1 SOUTH         77
##  5     869525     3937 04-SEP-17     1055355  1        1 SOUTH         88
##  6     922989     2356 13-OCT-17     4285485  2.87     1 WEST          93
##  7     732544      694 31-MAY-17        8511  0.64     1 CENTRAL       74
##  8     536185     3728 14-JAN-17       85939  1        1 SOUTH         54
##  9     967914      887 15-NOV-17     3775301  4.69     1 CENTRAL       98
## 10     102995      574 27-DEC-17       72765  1.29     1 EAST         104
## # ... with 1,857,557 more rows, and 1 more variable: year &lt;int&gt;
```

]

---

# Filtering variables

.bold[We can filter our data set based on given conditions for one or more variables with .font140.grey[`filter()`]]

&lt;br&gt;&lt;br&gt;

.center[.font200[.grey[`filter(`].blue[`data`]`,` .red[`...`] .grey[`)`]]]

&lt;br&gt;

.white[.center[.content-box-grey-dark[dplyr function] .content-box-blue-dark[data frame to transform] .content-box-red-dark[conditions to filter data]]]

---

# Filtering variables

.bold[We can filter our data set based on given conditions for one or more variables with .font140.grey[`filter()`]]

.scrollable90[


```r
# filter for all observations in month 1 (January)
filter(transactions, hshd_num == "3708")
## # A tibble: 565 x 9
##    basket_num hshd_num purchase_ product_num spend units store_r week_num
##         &lt;int&gt;    &lt;int&gt; &lt;chr&gt;           &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;      &lt;int&gt;
##  1     100369     3708 09-DEC-17       93466  3.18     2 SOUTH        101
##  2     636498     3708 25-MAR-17     1107634  1.29     1 SOUTH         64
##  3     546082     3708 21-JAN-17     1107675  1.5      6 SOUTH         55
##  4     684954     3708 29-APR-17     5972414  2.49     1 SOUTH         69
##  5     616834     3708 11-MAR-17     3688758  1.49     1 SOUTH         62
##  6     717587     3708 20-MAY-17       93484  0.99     1 SOUTH         72
##  7     636498     3708 25-MAR-17     3816309  1.78     2 SOUTH         64
##  8     963134     3708 11-NOV-17     5867925  8.37     3 SOUTH         97
##  9     758341     3708 18-JUN-17     6487780  1.99     1 SOUTH         77
## 10     955303     3708 04-NOV-17     4896971  1        1 SOUTH         96
## # ... with 555 more rows, and 1 more variable: year &lt;int&gt;

# filter for all observations on January 1st
filter(transactions, hshd_num == "3708", spend &gt; 3)
## # A tibble: 197 x 9
##    basket_num hshd_num purchase_ product_num spend units store_r week_num
##         &lt;int&gt;    &lt;int&gt; &lt;chr&gt;           &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;      &lt;int&gt;
##  1     100369     3708 09-DEC-17       93466  3.18     2 SOUTH        101
##  2     963134     3708 11-NOV-17     5867925  8.37     3 SOUTH         97
##  3     973940     3708 18-NOV-17       85383  6.96     8 SOUTH         98
##  4     955303     3708 04-NOV-17      633008  3.29     1 SOUTH         96
##  5     896784     3708 23-SEP-17       85383  5.53     7 SOUTH         90
##  6     564871     3708 04-FEB-17     5510044  3.69     1 SOUTH         57
##  7     806865     3708 22-JUL-17     5849247  3.79     1 SOUTH         81
##  8     934452     3708 21-OCT-17       85383  6.09     7 SOUTH         94
##  9     747396     3708 10-JUN-17      933615  8.99     1 SOUTH         75
## 10     747396     3708 10-JUN-17     5235072  4.19     1 SOUTH         75
## # ... with 187 more rows, and 1 more variable: year &lt;int&gt;

# filter for all observations on January 1st with a departure delay
filter(transactions, hshd_num == "3708", spend &gt; 3, product_num != 85383)
## # A tibble: 176 x 9
##    basket_num hshd_num purchase_ product_num spend units store_r week_num
##         &lt;int&gt;    &lt;int&gt; &lt;chr&gt;           &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;      &lt;int&gt;
##  1     100369     3708 09-DEC-17       93466  3.18     2 SOUTH        101
##  2     963134     3708 11-NOV-17     5867925  8.37     3 SOUTH         97
##  3     955303     3708 04-NOV-17      633008  3.29     1 SOUTH         96
##  4     564871     3708 04-FEB-17     5510044  3.69     1 SOUTH         57
##  5     806865     3708 22-JUL-17     5849247  3.79     1 SOUTH         81
##  6     747396     3708 10-JUN-17      933615  8.99     1 SOUTH         75
##  7     747396     3708 10-JUN-17     5235072  4.19     1 SOUTH         75
##  8     896784     3708 23-SEP-17     6139597  5.99     1 SOUTH         90
##  9     737913     3708 03-JUN-17      103780 11.0      1 SOUTH         74
## 10     519995     3708 02-JAN-17     2956277  5        2 SOUTH         53
## # ... with 166 more rows, and 1 more variable: year &lt;int&gt;
```

]

---

# Save new data frame

.bold[dplyr functions .red[do not] over-write data; must save to a new data frame object.]


```r
hshd_3708 &lt;- filter(transactions, hshd_num == "3708")
hshd_3708
## # A tibble: 565 x 9
##    basket_num hshd_num purchase_ product_num spend units store_r week_num
##         &lt;int&gt;    &lt;int&gt; &lt;chr&gt;           &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;      &lt;int&gt;
##  1     100369     3708 09-DEC-17       93466  3.18     2 SOUTH        101
##  2     636498     3708 25-MAR-17     1107634  1.29     1 SOUTH         64
##  3     546082     3708 21-JAN-17     1107675  1.5      6 SOUTH         55
##  4     684954     3708 29-APR-17     5972414  2.49     1 SOUTH         69
##  5     616834     3708 11-MAR-17     3688758  1.49     1 SOUTH         62
##  6     717587     3708 20-MAY-17       93484  0.99     1 SOUTH         72
##  7     636498     3708 25-MAR-17     3816309  1.78     2 SOUTH         64
##  8     963134     3708 11-NOV-17     5867925  8.37     3 SOUTH         97
##  9     758341     3708 18-JUN-17     6487780  1.99     1 SOUTH         77
## 10     955303     3708 04-NOV-17     4896971  1        1 SOUTH         96
## # ... with 555 more rows, and 1 more variable: year &lt;int&gt;
```

---

# Comparison operators

.bold[We can use multiple comparison operators for our condition statements]

.pull-left[

.center[.font120[.bold[`?Comparison`]]]

.font90[
Function  | Description
------- | ------
`&lt;` | less than
`&gt;` | greater than
`==` | equal to
`&lt;=` | less than or equal to
`&gt;=` | greater than or equal to
`!=` | not equal to
`%in%` | group membership
`is.na` | is missing
`!is.na` | is not missing
]
]

--

.pull-right[

.center[.font120[.bold[What will these produce?]]]


```r
filter(transactions, week_num == 12)
filter(transactions, week_num != 12)
filter(transactions, week_num %in% c(1, 5, 10))
filter(transactions, spend &lt;= 5)
filter(transactions, !(spend &lt;= 5))
filter(transactions, is.na(spend))
```

]

---

# Multiple comparison operators

.bold[And we can combine multiple comparison operators]

.pull-left-40[

.center[.font120[.bold[`?base::Logic`]]]

Function  | Description
:------: | ------------
`&amp;` | boolean and
&amp;#x7c; | boolean or
`!` | not
`any` | any are true
`all` | all are true

]

--

.pull-right-60[

.center[.font120[.bold[What will these produce?]]]


```r
# set 1
filter(transactions, week == 1, store_r == "SOUTH")
filter(transactions, week == 1 &amp; store_r == "SOUTH")

# set 2
filter(transactions, store_r == "SOUTH" | store_r == "NORTH")
filter(transactions, store %in% c("SOUTH", "NORTH"))

# set 3 --&gt; are these the same?
filter(transactions, !(week_num &lt; 50 | spend &gt; 2))
filter(transactions, week_num &gt;= 50, spend &lt;= 2)
```

]

---

# Two common mistakes <span>&lt;i class="fas  fa-exclamation-triangle faa-pulse animated faa-slow " style=" color:red;"&gt;&lt;/i&gt;</span>

.pull-left[

.center.font130[Using .red[=] instead of .green[==]]


```r
# wrong
filter(transactions, store_r = "SOUTH")

# correct
filter(transactions, store_r == "SOUTH")
```


]

.pull-right[

.center.font130[Forgetting quotes]


```r
# wrong
filter(transactions, store_r == SOUTH)

# correct
filter(transactions, store_r == "SOUTH")
```

]

---
class: yourturn

# Your Turn!

.pull-left[

### Challenge
.font110[
1. Import the transactions.csv file.

2. Filter for transactions with greater than 2 units.

3. Filter for transactions with greater than 2 units during week 101 that occurred in the south region.

4. Filter for transactions with greater than 2 units during week 101 that occurred in the south or central regions.
]
]

--

.pull-right[

### Solution


```r
# 1: import the data
transactions &lt;- read_csv("data/transactions.csv")

# 2: filter for transactions with greater than 2 units
filter(transactions, units &gt; 2)

# 3: for transactions with greater than 2 units during week 101 that occurred in the south region.
filter(transactions, units &gt; 2, week_num == 101, store_r == "SOUTH")

# 4: for transactions with greater than 2 units during week 101 that occurred in the south or central regions.
filter(transactions, units &gt; 2, week_num == 101, store_r %in% c("SOUTH", "CENTRAL"))
```

]

---

# Selecting variables

.bold[We can select variables of interest with the .font130.grey[`select()`] function]

&lt;br&gt;&lt;br&gt;

.center[.font200[.grey[`select(`].blue[`data`]`,` .red[`...`] .grey[`)`]]]

&lt;br&gt;

.white[.center[.content-box-grey[dplyr function] .content-box-blue[data frame to transform] .content-box-red-dark[names of columns to extract]]]

---

# Selecting variables

.bold[We can select variables of interest with the .font130.grey[`select()`] function]

.scrollable90[


```r
select(transactions, product_num, spend, units, store_r, week_num)
## # A tibble: 1,857,567 x 5
##    product_num spend units store_r week_num
##          &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;      &lt;int&gt;
##  1       93466  3.18     2 SOUTH        101
##  2       85201  3.49     1 CENTRAL       90
##  3     2507006  0.89     1 CENTRAL       62
##  4     4819172  8.99     1 SOUTH         77
##  5     1055355  1        1 SOUTH         88
##  6     4285485  2.87     1 WEST          93
##  7        8511  0.64     1 CENTRAL       74
##  8       85939  1        1 SOUTH         54
##  9     3775301  4.69     1 CENTRAL       98
## 10       72765  1.29     1 EAST         104
## # ... with 1,857,557 more rows

# produces same as above
select(transactions, product_num:week_num)
## # A tibble: 1,857,567 x 5
##    product_num spend units store_r week_num
##          &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;      &lt;int&gt;
##  1       93466  3.18     2 SOUTH        101
##  2       85201  3.49     1 CENTRAL       90
##  3     2507006  0.89     1 CENTRAL       62
##  4     4819172  8.99     1 SOUTH         77
##  5     1055355  1        1 SOUTH         88
##  6     4285485  2.87     1 WEST          93
##  7        8511  0.64     1 CENTRAL       74
##  8       85939  1        1 SOUTH         54
##  9     3775301  4.69     1 CENTRAL       98
## 10       72765  1.29     1 EAST         104
## # ... with 1,857,557 more rows
```


.center[.content-box-gray[.bold[You can also deselect variables: `select(transactions -(product_num:week_num))`]]]

]

---

# Select .red[helper] functions

.bold[The real beauty of .font130[`select()`] is in the helper functions.]
.scrollable90[
.pull-left[

### Helper functions

Function  | Description
:------: | ------------
`starts_with()` | select columns whose name starts with
`ends_with()` | select columns whose name ends with
`contains()` | select columns whose name contains with
`matches()` | select columns whose name matches a regular expression

...and more (see `?tidyselect::select_helpers`)

]

.pull-right[

### Examples


```r
# starts with example
select(transactions, ends_with("num"))
## # A tibble: 1,857,567 x 4
##    basket_num hshd_num product_num week_num
##         &lt;int&gt;    &lt;int&gt;       &lt;int&gt;    &lt;int&gt;
##  1     100369     3708       93466      101
##  2     891779      719       85201       90
##  3     609562     4995     2507006       62
##  4     760220       44     4819172       77
##  5     869525     3937     1055355       88
##  6     922989     2356     4285485       93
##  7     732544      694        8511       74
##  8     536185     3728       85939       54
##  9     967914      887     3775301       98
## 10     102995      574       72765      104
## # ... with 1,857,557 more rows

# ends with example
select(transactions, contains("_"))
## # A tibble: 1,857,567 x 6
##    basket_num hshd_num purchase_ product_num store_r week_num
##         &lt;int&gt;    &lt;int&gt; &lt;chr&gt;           &lt;int&gt; &lt;chr&gt;      &lt;int&gt;
##  1     100369     3708 09-DEC-17       93466 SOUTH        101
##  2     891779      719 20-SEP-17       85201 CENTRAL       90
##  3     609562     4995 07-MAR-17     2507006 CENTRAL       62
##  4     760220       44 19-JUN-17     4819172 SOUTH         77
##  5     869525     3937 04-SEP-17     1055355 SOUTH         88
##  6     922989     2356 13-OCT-17     4285485 WEST          93
##  7     732544      694 31-MAY-17        8511 CENTRAL       74
##  8     536185     3728 14-JAN-17       85939 SOUTH         54
##  9     967914      887 15-NOV-17     3775301 CENTRAL       98
## 10     102995      574 27-DEC-17       72765 EAST         104
## # ... with 1,857,557 more rows

# combining different select helpers
select(transactions, c(year, ends_with("num"), contains("_")))
## # A tibble: 1,857,567 x 7
##     year basket_num hshd_num product_num week_num purchase_ store_r
##    &lt;int&gt;      &lt;int&gt;    &lt;int&gt;       &lt;int&gt;    &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;  
##  1  2017     100369     3708       93466      101 09-DEC-17 SOUTH  
##  2  2017     891779      719       85201       90 20-SEP-17 CENTRAL
##  3  2017     609562     4995     2507006       62 07-MAR-17 CENTRAL
##  4  2017     760220       44     4819172       77 19-JUN-17 SOUTH  
##  5  2017     869525     3937     1055355       88 04-SEP-17 SOUTH  
##  6  2017     922989     2356     4285485       93 13-OCT-17 WEST   
##  7  2017     732544      694        8511       74 31-MAY-17 CENTRAL
##  8  2017     536185     3728       85939       54 14-JAN-17 SOUTH  
##  9  2017     967914      887     3775301       98 15-NOV-17 CENTRAL
## 10  2017     102995      574       72765      104 27-DEC-17 EAST   
## # ... with 1,857,557 more rows
```


]
]

---
class: yourturn

# Your Turn!


.pull-left[

### Challenge

1. Import the __households.csv__ data and...

2. Select all columns that contain "_" and...

3. Filter for those observations that fall in the "75-99K" income range. 

]

--

.pull-right[

### Solution


```r
# 1. Import the __households.csv__ data
households &lt;- read_csv("data/households.csv")

# 2. Select all columns that contain "_"
reduced_df &lt;- select(households, contains("_"))

#3. Filter for those observations that fall in the "75-99K" income range
filter(reduced_df, income_range == "75-99K")
## # A tibble: 594 x 5
##    hshd_num age_range     income_range hshd_composition hh_size
##    &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;        &lt;chr&gt;            &lt;chr&gt;  
##  1 1171     75+           75-99K       &lt;NA&gt;             null   
##  2 1531     75+           75-99K       &lt;NA&gt;             null   
##  3 1580     35-44         75-99K       &lt;NA&gt;             null   
##  4 2902     35-44         75-99K       &lt;NA&gt;             null   
##  5 1093     45-54         75-99K       &lt;NA&gt;             null   
##  6 2377     45-54         75-99K       &lt;NA&gt;             null   
##  7 4402     45-54         75-99K       &lt;NA&gt;             null   
##  8 4639     45-54         75-99K       &lt;NA&gt;             null   
##  9 4762     65-74         75-99K       &lt;NA&gt;             null   
## 10 0269     NOT AVAILABLE 75-99K       &lt;NA&gt;             null   
## # ... with 584 more rows
```

]

---

# Arranging data based on values

.bold[We can select variables of interest with the .font130.grey[`arrange()`] function]

&lt;br&gt;&lt;br&gt;

.center[.font200[.grey[`arrange(`].blue[`data`]`,` .red[`...`] .grey[`)`]]]

&lt;br&gt;

.white[.center[.content-box-grey[dplyr function] .content-box-blue[data frame to transform] .content-box-red-dark[one or more columns to order by]]]

---

# Arranging data based on values

.bold[We can select variables of interest with the .font130.grey[`arrange()`] function]

.pull-left[

### Ascending order


```r
arrange(transactions, spend)
## # A tibble: 1,857,567 x 9
##    basket_num hshd_num purchase_ product_num spend units store_r week_num
##         &lt;int&gt;    &lt;int&gt; &lt;chr&gt;           &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;      &lt;int&gt;
##  1     100791     1592 10-DEC-17     5895132 -15.0    -1 WEST         102
##  2     995139     2215 03-DEC-17     6530599 -15.0    -1 WEST         101
##  3     809392      511 24-JUL-17     5280421 -15.0    -1 CENTRAL       82
##  4     543439     3309 18-JAN-17     6476706 -15.0    -1 SOUTH         55
##  5     844999     2776 18-AUG-17     4353736 -15.0    -1 WEST          85
##  6     102640     4078 23-DEC-17     6298451 -15.0    -1 EAST         103
##  7     738866     3293 03-JUN-17     6548638 -15.0    -1 SOUTH         74
##  8     579085     1346 13-FEB-17     6186554 -15.0    -1 EAST          59
##  9     101952     4599 18-DEC-17     6634374 -15.0    -1 SOUTH        103
## 10     545229     2106 19-JAN-17     6148132 -15.0    -1 WEST          55
## # ... with 1,857,557 more rows, and 1 more variable: year &lt;int&gt;
```


]

.pull-right[

### Descending order


```r
arrange(transactions, desc(spend))
## # A tibble: 1,857,567 x 9
##    basket_num hshd_num purchase_ product_num spend units store_r week_num
##         &lt;int&gt;    &lt;int&gt; &lt;chr&gt;           &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;      &lt;int&gt;
##  1     526404      985 05-JAN-17     3764235  282.    10 CENTRAL       53
##  2     101308     3977 17-DEC-17     3319279  276.     4 EAST         103
##  3     921333     3934 11-OCT-17     5232147  260.     1 EAST          93
##  4     849384     2775 21-AUG-17     6298353  250.     1 WEST          86
##  5     646596      985 01-APR-17     3764235  226.     8 CENTRAL       65
##  6     799338      985 16-JUL-17     3764235  226.     8 CENTRAL       81
##  7     791836       63 12-JUL-17       86471  210     84 EAST          80
##  8     985855     1270 26-NOV-17     6659474  210.     1 EAST         100
##  9     842832     1238 15-AUG-17      153329  204.    24 EAST          85
## 10     773947     1730 30-JUN-17     1356008  183      7 EAST          78
## # ... with 1,857,557 more rows, and 1 more variable: year &lt;int&gt;
```

]

---

# Arrange .red[.bold[always]] places missing values at bottom

.pull-left[


```r
(df &lt;- tibble(x = c(5, 2, 5, NA)))
## # A tibble: 4 x 1
##       x
##   &lt;dbl&gt;
## 1     5
## 2     2
## 3     5
## 4    NA
```

]

.pull-right[


```r
arrange(df, x)
## # A tibble: 4 x 1
##       x
##   &lt;dbl&gt;
## 1     2
## 2     5
## 3     5
## 4    NA
arrange(df, desc(x))
## # A tibble: 4 x 1
##       x
##   &lt;dbl&gt;
## 1     5
## 2     5
## 3     2
## 4    NA
```

]

---
class: yourturn

# Your Turn!

.pull-left[

### Challenge

1. Arrange __transactions__ by `week_num` in ascending order.

2. Arrange __transactions__ by `week_num` in ascending order and `spend` in descending order.

3. What happens when you arrange an alphabetical variable such as `store_r`?

]

--

.pull-right[

### Solution


```r
# 1: arrange transactions by week_num in ascending order
arrange(transactions, week_num)

# 2: arrange transactions by week_num in ascending order and spend in descending order
arrange(transactions, week_num, desc(spend))

# 3: What happens when you arrange an alphabetical variable such as store_r?
arrange(transactions, desc(store_r))
```

]

---

# Compute summary statistics

.bold[We can compute summary statistics with the .font130.grey[`summarize()`] function]


&lt;br&gt;&lt;br&gt;

.center[.font200[.grey[`summarize(`].blue[`data`]`,` .red[`...`] .grey[`)`]]]

&lt;br&gt;

.white[.center[.content-box-grey[dplyr function] .content-box-blue[data frame to transform] .content-box-red-dark[one or more summary statistics to compute]]]

---

# Compute summary statistics

.bold[We can compute summary statistics with the .font130.grey[`summarize()`] function]

.pull-left[

### single statistic


```r
summarize(transactions, avg_spend = mean(spend, na.rm = TRUE))
## # A tibble: 1 x 1
##   avg_spend
##       &lt;dbl&gt;
## 1      3.61
```

.center[.content-box-grey[.bold[What does `na.rm` do?]]]

]

--

.pull-right[

### multiple statistics


```r
summarize(transactions, 
  spend_avg = mean(spend, na.rm = TRUE),
  spend_sd  = sd(spend, na.rm = TRUE),
  n = n()
)
## # A tibble: 1 x 3
##   spend_avg spend_sd       n
##       &lt;dbl&gt;    &lt;dbl&gt;   &lt;int&gt;
## 1      3.61     3.91 1857567
```

]

---

# Summarize .red[helper] functions

.bold[There are a wide variety of functions you can use within .font130[`summarize()`]]


&lt;br&gt;

.pull-left[

.font80[
Function  | Description
------- | ------
`min()`, `max()` | min, max values in vector
`mean()` | mean value
`median()` | median value
`sum()` | sum of all vector values
`var()`, `sd()` | variance/std of vector
`first()`, `last()` | first/last value in vector
`nth()` | nth value in vector
`n()` | number of values in vector
`n_distinct()` | number of distinct values in vector

]
]

.pull-right[
&lt;br&gt;
&lt;img src="images/summarize_functions.png" width="100%" height="100%" style="display: block; margin: auto;" /&gt;

]

---


# Summarizing .red[grouped] data

.bold[Summary statistics become more powerful when we can compute and compare at different aggregated levels]

.pull-left[

#### Avg spend by week


```r
# group data
by_week &lt;- group_by(transactions, week_num)

# compute summary stat
summarize(by_week, spend_avg = mean(spend, na.rm = TRUE))
## # A tibble: 52 x 2
##    week_num spend_avg
##       &lt;int&gt;     &lt;dbl&gt;
##  1       53      3.51
##  2       54      3.49
##  3       55      3.55
##  4       56      3.48
##  5       57      3.54
##  6       58      3.59
##  7       59      3.74
##  8       60      3.58
##  9       61      3.58
## 10       62      3.60
## # ... with 42 more rows
```

]

.pull-right[

#### Variability of spend by store region


```r
# group data
by_region &lt;- group_by(transactions, store_r)

# compute summary stat
summarize(by_region, delay_sd = sd(spend, na.rm = TRUE))
## # A tibble: 4 x 2
##   store_r delay_sd
##   &lt;chr&gt;      &lt;dbl&gt;
## 1 CENTRAL     3.97
## 2 EAST        3.83
## 3 SOUTH       3.91
## 4 WEST        3.97
```

]


---
class: yourturn

# Your Turn!

.pull-left[

### Challenge

1. Compute the average `spend` by `hshd_num` and arrange in descending order to find the household with the largest average spend.

2. Find the `product_num`s with the largest median spend.

]

--

.pull-right[

### Solution


```r
# 1: Compute the average `spend` by `hshd_num` and arrange in descending order to find the household with the largest average spend.
hshd_group &lt;- group_by(transactions, hshd_num)
hshd_spend &lt;- summarize(hshd_group, spend_avg = mean(spend, na.rm = TRUE))
arrange(hshd_spend, desc(spend_avg))

# 2: Find the `product_num`s with the largest median spend.
prod_group &lt;- group_by(transactions, product_num)
prod_spend &lt;- summarize(prod_group, spend_median = median(spend, na.rm = TRUE))
arrange(prod_spend, desc(spend_median))
```

]

---

# The pipe operator .red[`%&gt;%`]

Going back to our last problem, our code was doing three things:

.pull-left[

.font120[
1. .blue[grouping by product number]

2. .orange[summarizing spend]

3. .purple[sorting spend by greatest to least]
]
]

.pull-right[



```r
# 1 grouping by product number
prod_group &lt;- group_by(transactions, product_num)

# 2 summarizing spend
prod_spend &lt;- summarize(prod_group, spend_median = median(spend, na.rm = TRUE))

# 3 sorting spend by greatest to least
arrange(prod_spend, desc(spend_median))
```

]

&lt;br&gt;&lt;br&gt;&lt;br&gt;

.center[.content-box-gray[.bold[Surely we can streamline our code and make it more efficient and legible!]]]


---

# The pipe operator .red[`%&gt;%`]

An alternative approach to perform these thing things:

.pull-left[

### Traditional approach

&lt;img src="images/function-traditional.png" width="80%" height="80%" style="display: block; margin: auto auto auto 0;" /&gt;



```r
prod_group &lt;- group_by(transactions, product_num)
prod_spend &lt;- summarize(prod_group, spend_median = median(spend, na.rm = TRUE))
arrange(prod_spend, desc(spend_median))
```

]

.pull-right[

### pipe (`%&gt;%`) approach

&lt;img src="images/function-pipe.png" width="90%" height="90%" style="display: block; margin: auto auto auto 0;" /&gt;


```r
transactions %&gt;%
  group_by(product_num) %&gt;%
  summarize(spend_median = median(spend, na.rm = TRUE)) %&gt;%
  arrange(desc(spend_median))
```

]

---

class: yourturn

# Your Turn!

.pull-left[

### Challenge
.font90[
Using the pipe operator follow these steps with the __transactions__ data:

1. filter for southern region stores only

2. group by product

3. compute the average spend

4. sort this output to find the product with the largest average spend
]
]

--

.pull-right[

### Solution


```r
transactions %&gt;%
  filter(store_r == "SOUTH") %&gt;%
  group_by(product_num) %&gt;%
  summarize(spend_avg = mean(spend, na.rm = TRUE)) %&gt;%
  arrange(desc(spend_avg))
## # A tibble: 44,883 x 2
##    product_num spend_avg
##          &lt;int&gt;     &lt;dbl&gt;
##  1     1144005     182. 
##  2     6482901     150. 
##  3      343329     143. 
##  4     6296414     119  
##  5     3764235      96.4
##  6     5649118      90.0
##  7     6138733      90.0
##  8     1452445      88.4
##  9     1226570      86.3
## 10     1367767      85.8
## # ... with 44,873 more rows
```

]

---

# Mutate variables

.bold[We can create new variables with the .font130.grey[`mutate()`] function]


&lt;br&gt;&lt;br&gt;

.center[.font200[.grey[`mutate(`].blue[`data`]`,` .red[`...`] .grey[`)`]]]

&lt;br&gt;

.white[.center[.content-box-grey[dplyr function] .content-box-blue[data frame to transform] .content-box-red-dark[one or more new variables to create]]]

---

# Mutate variables

.bold[We can create new variables with the .font130.grey[`mutate()`] function]


```r
*mutate(transactions, price_per_unit = spend / units) %&gt;%
  select(spend, units, price_per_unit, everything())
## # A tibble: 1,857,567 x 10
##    spend units price_per_unit basket_num hshd_num purchase_ product_num
##    &lt;dbl&gt; &lt;int&gt;          &lt;dbl&gt;      &lt;int&gt;    &lt;int&gt; &lt;chr&gt;           &lt;int&gt;
##  1  3.18     2           1.59     100369     3708 09-DEC-17       93466
##  2  3.49     1           3.49     891779      719 20-SEP-17       85201
##  3  0.89     1           0.89     609562     4995 07-MAR-17     2507006
##  4  8.99     1           8.99     760220       44 19-JUN-17     4819172
##  5  1        1           1        869525     3937 04-SEP-17     1055355
##  6  2.87     1           2.87     922989     2356 13-OCT-17     4285485
##  7  0.64     1           0.64     732544      694 31-MAY-17        8511
##  8  1        1           1        536185     3728 14-JAN-17       85939
##  9  4.69     1           4.69     967914      887 15-NOV-17     3775301
## 10  1.29     1           1.29     102995      574 27-DEC-17       72765
## # ... with 1,857,557 more rows, and 3 more variables: store_r &lt;chr&gt;,
## #   week_num &lt;int&gt;, year &lt;int&gt;
```

---

# Mutate variables

.bold[We can create .red[multiple] variables within one .font130.grey[`mutate()`] function]


```r
transactions %&gt;%
  group_by(week_num) %&gt;%
  summarize(
    spend = sum(spend, na.rm = TRUE),
    units = sum(units, na.rm = TRUE)
  ) %&gt;% 
* mutate(
*   avg_spend_per_unit = spend / units,
*   wow_perc_growth    = (avg_spend_per_unit / lag(avg_spend_per_unit)) - 1,
*   wtd_net_spend      = cumsum(spend),
*   wtd_net_units      = cumsum(units)
* )
## # A tibble: 52 x 7
##    week_num  spend units avg_spend_per_uâ¦ wow_perc_growth wtd_net_spend
##       &lt;int&gt;  &lt;dbl&gt; &lt;int&gt;            &lt;dbl&gt;           &lt;dbl&gt;         &lt;dbl&gt;
##  1       53 1.31e5 48538             2.71        NA             131328.
##  2       54 1.26e5 46761             2.68        -0.00802       256833.
##  3       55 1.29e5 46961             2.74         0.0203        385436.
##  4       56 1.22e5 45640             2.67        -0.0234        507492.
##  5       57 1.35e5 49397             2.73         0.0206        642319.
##  6       58 1.27e5 45594             2.79         0.0215        769444.
##  7       59 1.35e5 46514             2.89         0.0378        904042.
##  8       60 1.22e5 44098             2.78        -0.0410       1026422.
##  9       61 1.26e5 45549             2.76        -0.00629      1152033.
## 10       62 1.31e5 47446             2.77         0.00478      1283502.
## # ... with 42 more rows, and 1 more variable: wtd_net_units &lt;int&gt;
```

---

# Mutate helper functions

.bold[There are a wide variety of functions you can use within .font130.grey[`mutate()`]]

_.blue[Must be vectorized functions - meaning the function must take a vector of values as input and return the same number of values as output.]_
.scrollable[
.pull-left[

.font80[
Function  | Description
------- | ------
`+,-,*,/,^` | arithmetic
`x / sum(x)` | arithmetic w/aggregation
`%/%, %%` | modular arithmetic
`log, exp, sqrt` | transformations
`lag, lead` | offsets
`cumsum, cumprod, cum...` | cum/rolling aggregates
`&gt;, &gt;=, &lt;, &lt;=, !=, ==` | logical comparisons
`min_rank, dense_rank` | ranking
`between` | are values between a and b?
`ntile` | bin values into n buckets
]
]

.pull-right[


```r
# mean center data
transmute(transactions, center_spend = spend / mean(spend, na.rm = TRUE))
## # A tibble: 1,857,567 x 1
##    center_spend
##           &lt;dbl&gt;
##  1        0.880
##  2        0.966
##  3        0.246
##  4        2.49 
##  5        0.277
##  6        0.794
##  7        0.177
##  8        0.277
##  9        1.30 
## 10        0.357
## # ... with 1,857,557 more rows

# transform values
transmute(transactions,
  log_spend = log(spend),
  exp_spend = exp(spend))
## # A tibble: 1,857,567 x 2
##    log_spend exp_spend
##        &lt;dbl&gt;     &lt;dbl&gt;
##  1     1.16      24.0 
##  2     1.25      32.8 
##  3    -0.117      2.44
##  4     2.20    8022.  
##  5     0          2.72
##  6     1.05      17.6 
##  7    -0.446      1.90
##  8     0          2.72
##  9     1.55     109.  
## 10     0.255      3.63
## # ... with 1,857,557 more rows

# lag and cumsum values
transmute(transactions,
  spend     = spend,
  lag_spend = lag(spend),
  sum_spend = cumsum(spend))
## # A tibble: 1,857,567 x 3
##    spend lag_spend sum_spend
##    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
##  1  3.18     NA         3.18
##  2  3.49      3.18      6.67
##  3  0.89      3.49      7.56
##  4  8.99      0.89     16.6 
##  5  1         8.99     17.6 
##  6  2.87      1        20.4 
##  7  0.64      2.87     21.1 
##  8  1         0.64     22.1 
##  9  4.69      1        26.8 
## 10  1.29      4.69     28.0 
## # ... with 1,857,557 more rows
```

]
]

---

class: yourturn

# Your Turn!

.pull-left[

### Challenge
.font90[
Using what you've learned thus far, can you find the store region and week that experienced the greatest week over week growth in the number of units sold?

Hint:


```r
transactions %&gt;%
  group_by(______, ______) %&gt;%
  summarize(______) %&gt;%
  mutate(______) %&gt;%
  arrange(______)
```

]
]

--

.pull-right[

### Solution


```r
transactions %&gt;%
  group_by(store_r, week_num) %&gt;%
  summarize(units = sum(units)) %&gt;%
  mutate(
    wow_units = units - lag(units),
    wow_perc  = (units / lag(units) - 1)
    ) %&gt;%
  arrange(desc(wow_perc))
## # A tibble: 208 x 5
## # Groups:   store_r [4]
##    store_r week_num units wow_units wow_perc
##    &lt;chr&gt;      &lt;int&gt; &lt;int&gt;     &lt;int&gt;    &lt;dbl&gt;
##  1 EAST         103 18806      4008    0.271
##  2 SOUTH        103 11693      2271    0.241
##  3 WEST         103 14103      2556    0.221
##  4 SOUTH         67 10923      1945    0.217
##  5 CENTRAL       67 12532      2043    0.195
##  6 CENTRAL      103 13179      2065    0.186
##  7 EAST          67 16212      2316    0.167
##  8 SOUTH         88 11275      1591    0.164
##  9 WEST          61 12508      1643    0.151
## 10 WEST          57 13389      1610    0.137
## # ... with 198 more rows
```

]

---

# Key things to remember

.pull-left[

* .bold[`filter`]: pick observations based on values

* .bold[`select`]: pick variables

* .bold[`summarize`]: compute statistical summaries 

* .bold[`group_by`]: perform operations at different levels of your data

* .bold[`arrange`]: reorder data

* .bold[`mutate`]: create new variables

&lt;br&gt;

.center[.content-box-gray[knit them all together with .bold[%&gt;%]]]

]

.pull-right[

&lt;br&gt;&lt;br&gt;
&lt;img src="images/information-overload.jpg" width="640" style="display: block; margin: auto;" /&gt;


]

---

# Key things to remember

.pull-left[

&lt;img src="images/cheatsheet-dplyr.png" width="1460" style="display: block; margin: auto;" /&gt;


]

.pull-right[

&lt;br&gt;&lt;br&gt;
&lt;img src="images/information-overload.jpg" width="640" style="display: block; margin: auto;" /&gt;

&lt;br&gt;

]

.center[.content-box-gray[.bold[`Help &gt;&gt; Cheatsheets &gt;&gt; Data Transformation with dplyr`]]]

---

# Questions?

&lt;br&gt;

&lt;img src="images/questions.png" width="450" height="450" style="display: block; margin: auto;" /&gt;

---

# Lunch time <span style=" display: -moz-inline-stack; display: inline-block; transform: rotate(0deg);">&lt;img src="https://emojis.slackmojis.com/emojis/images/1450694616/220/bananadance.gif?1450694616" style="height:1em; width:auto; "/&gt;</span>

&lt;img src="images/lunchtime-day1.gif" width="90%" style="display: block; margin: auto;" /&gt;

---
class: clear, center, middle


background-image: url(images/time-for-review.jpg)
background-size: cover

---


class: clear, center, middle


background-image: url(https://raw.githubusercontent.com/bradleyboehmke/Dayton-Weather-2018/master/Dayton_Weather.png)
background-size: cover

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

.font200.bold[Visualizing Data]

---

# ggplot
&lt;br&gt;
.pull-left[
&lt;br&gt;
* R has several systems for making graphs

* `ggplot2` is the most elegant and versatile

* Implements the grammar of graphics theory behind data visualization
]

.pull-right[

&lt;img src="images/ggplot2.png" width="50%" height="50%" style="display: block; margin: auto;" /&gt;

]

---

# Basics

`ggplot2` works with a layer based mentality:

.pull-left[

```r
ggplot(data, aes(x, y)) +
  geom_xxx() +
  scale_xxx() +
  facet_xxx() +
  ggtitle()
```
]

--

.pull-right[


```r
ggplot(data = txhousing, aes(x = volume, y = median)) + 
  geom_point(alpha = .1) +
  scale_y_continuous(name = "Median Sales Price", labels = scales::dollar) +
  scale_x_log10(name = "Total Sales Volume", labels = scales::comma) +
  ggtitle("Texas Housing Sales", subtitle = "Sales data from 2000-2010 provided by the TAMU real estate center")
```

&lt;img src="slides-source_files/figure-html/example-ggplot-1.png" style="display: block; margin: auto;" /&gt;

]

---


# Prerequisites

.pull-left[
### Packages


```r
library(ggplot2) # or library(tidyverse)
```

]

.pull-right[

### Example Data


```r
# built-in data set
mpg
```

### Exercise Data


```r
transactions
```

]

---

# Canvas layer

.bold[We can create a "canvas" for our plot with...]

.pull-left[


```r
ggplot(data = mpg)
```

&lt;img src="slides-source_files/figure-html/unnamed-chunk-66-1.png" style="display: block; margin: auto;" /&gt;


]

.pull-right[


```r
ggplot(data = mpg, aes(x = displ, y = hwy))
```

&lt;img src="slides-source_files/figure-html/unnamed-chunk-67-1.png" style="display: block; margin: auto;" /&gt;

]

.center[.content-box-gray[.bold[We use .red[aes()] to map attributes to our plot]]]

---

# Plotting our data with .red[geoms]

.pull-left[
* We display data with geometric shapes

* ~ 30 built-in geoms (with many more offered by other pkgs)
   - `geom_point()`
   - `geom_line()`
   - `geom_histogram()`
   - `geom_density()`
   - `geom_freqpoly()`
   - `geom_boxplot()`
   - `geom_violin()`
   - `geom_bar()`
   - `geom_count()`
   - `geom_smooth()`

.center[.content-box-gray[.bold[See full list with `geom_` + tab]]]
]

---

# Plotting our data with .red[geoms]

.pull-left[
* We display data with geometric shapes

* ~ 30 built-in geoms (with many more offered by other pkgs)
   - `geom_point()`
   - `geom_line()`
   - .blue[.bold[`geom_histogram()`]]
   - .blue[.bold[`geom_density()`]]
   - .blue[.bold[`geom_freqpoly()`]]
   - `geom_boxplot()`
   - `geom_violin()`
   - `geom_bar()`
   - `geom_count()`
   - `geom_smooth()`

.center[.content-box-gray[.bold[See full list with `geom_` + tab]]]
]

.pull-right[
&lt;br&gt;&lt;br&gt;

```r
ggplot(data = mpg, aes(x = hwy)) +
  geom_histogram()

ggplot(data = mpg, aes(x = hwy)) +
  geom_freqpoly()

ggplot(data = mpg, aes(x = hwy)) +
  geom_density()
```

&lt;img src="slides-source_files/figure-html/unnamed-chunk-69-1.png" style="display: block; margin: auto;" /&gt;

]

---

# Plotting our data with .red[geoms]

.pull-left[
* We display data with geometric shapes

* ~ 30 built-in geoms (with many more offered by other pkgs)
   - `geom_point()`
   - `geom_line()`
   - `geom_histogram()`
   - `geom_density()`
   - `geom_freqpoly()`
   - .blue[.bold[`geom_boxplot()`]]
   - .blue[.bold[`geom_violin()`]]
   - .blue[.bold[`geom_bar()`]]
   - `geom_count()`
   - `geom_smooth()`

.center[.content-box-gray[.bold[See full list with `geom_` + tab]]]
]

.pull-right[
&lt;br&gt;&lt;br&gt;

```r
ggplot(data = mpg, aes(x = displ, y = hwy)) +
  geom_point()

ggplot(data = mpg, aes(x = class, y = hwy)) +
  geom_boxplot()

ggplot(data = mpg, aes(x = class, y = hwy)) +
  geom_violin()
```

&lt;img src="slides-source_files/figure-html/unnamed-chunk-71-1.png" style="display: block; margin: auto;" /&gt;

]

---

# Plotting our data with .red[geoms]

.pull-left[
* We display data with geometric shapes

* ~ 30 built-in geoms (with many more offered by other pkgs)
   - .blue[.bold[`geom_point()`]]
   - `geom_line()`
   - .blue[.bold[`geom_histogram()`]]
   - `geom_density()`
   - `geom_freqpoly()`
   - `geom_boxplot()`
   - `geom_violin()`
   - `geom_bar()`
   - `geom_count()`
   - `geom_smooth()`

]

.pull-right[
&lt;br&gt;&lt;br&gt;

```r
*ggplot(data = mpg, aes(x = displ, y = hwy)) +
  geom_point()

*ggplot(data = mpg, aes(x = hwy)) +
  geom_histogram()
```

&lt;img src="slides-source_files/figure-html/unnamed-chunk-73-1.png" style="display: block; margin: auto;" /&gt;

.center[.content-box-gray[.bold[Some geoms only require .font130[`x`], others .font130[`x`] &amp; .font130[`y`]]]]

]

---

class: yourturn

# Your Turn!

.pull-left[

### Challenge

Using the __transactions__ data:

1. Create a chart that illustrates the distribution of the spend variable.

2. Create a chart that shows the counts for each store region

3. Create a scatter plot of units vs spend 
]

--

.pull-right[

### Solutions


```r
#1: distribution of spend variable
ggplot(data = transactions, aes(x = spend)) +
    geom_histogram()

#2: distribution of store region variable
ggplot(data = transactions, aes(x = store_r)) +
 geom_bar()

#3: scatter plot for units vs spend
ggplot(data = transactions, aes(x = units, y = spend)) +
 geom_point()
```

&lt;img src="slides-source_files/figure-html/unnamed-chunk-75-1.png" style="display: block; margin: auto;" /&gt;

]

---

# Non-mapping aesthetics

.pull-left[

We can also change other visual aesthetics in our plots:

* .blue[c].orange[o].gray[l].purple[o].red[r]

* .font70[s].font120[i]z.font110[e] 

* sh&amp;#9653;pe (0-25 `?pch`)

* .opacity[opacity]
]

--

.pull-right[
&lt;br&gt;

```r
ggplot(data = mpg, aes(x = displ, y = hwy)) +
  geom_point(color = "blue", size = 2, shape = 17, alpha = .5)
```

&lt;img src="slides-source_files/figure-html/unnamed-chunk-76-1.png" style="display: block; margin: auto;" /&gt;

.center[.content-box-gray[.bold[But why are some points darker? ð¤]]]

]

---

# Non-mapping aesthetics

.pull-left[

We can also change other visual aesthetics in our plots:

* .blue[c].orange[o].gray[l].purple[o].red[r]

* .font70[s].font120[i]z.font110[e] 

* sh&amp;#9653;pe (0-25 `?pch`)

* .opacity[opacity]
]


.pull-right[
&lt;br&gt;

```r
ggplot(data = mpg, aes(x = displ, y = hwy)) +
* geom_jitter(color = "blue", size = 2, shape = 17, alpha = .5, width = .5)
```

&lt;img src="slides-source_files/figure-html/unnamed-chunk-77-1.png" style="display: block; margin: auto;" /&gt;

.center[.content-box-gray[.bold[Ahhhhhh, I see ð]]]

]


---

# Adding a 3&lt;sup&gt;rd&lt;/sup&gt; dimension

.bold[By moving the color argument to within aes(), we can map a 3rd variable to our plot]

.pull-left[

#### Non-mapping color aesthetic


```r
ggplot(data = mpg, aes(x = displ, y = hwy)) +
* geom_point(color = "blue")
```

&lt;img src="slides-source_files/figure-html/unnamed-chunk-78-1.png" style="display: block; margin: auto;" /&gt;

]

.pull-right[

#### Mapping color aesthetic to class variable


```r
*ggplot(data = mpg, aes(x = displ, y = hwy, color = class)) +
  geom_point()
```

&lt;img src="slides-source_files/figure-html/mapping-ggplot-1.png" style="display: block; margin: auto;" /&gt;

]

---
class: yourturn

# Your Turn!

.pull-left[

### Challenge

1. Create a scatter plot of `units` vs `spend` and color all points blue.

2. Create a scatter plot of `units` vs `spend` and color all points based on store region.
]

--

.pull-right[

### Solution


```r
#1 left
ggplot(transactions, aes(x = units, y = spend)) + 
  geom_point(color = "blue")

#2 right
ggplot(transactions, aes(x = units, y = spend, color = store_r)) + 
  geom_point()
```

&lt;img src="slides-source_files/figure-html/unnamed-chunk-80-1.png" style="display: block; margin: auto;" /&gt;

]

---

# Creating small multiples with .red[facets]

.bold[The `facet_xxx()` functions provide a simple way to create small multiples.]

--
.scrollable90[
.pull-left[

.bold[`facet_wrap()`]: primarily used to create small multiples based on a single variable


```r
ggplot(data = mpg, aes(x = displ, y = hwy)) + 
  geom_point() + 
* facet_wrap(~ class, nrow = 2)
```

&lt;img src="slides-source_files/figure-html/unnamed-chunk-81-1.png" style="display: block; margin: auto;" /&gt;

]

.pull-right[

.bold[`facet_grid()`]: primarily used to create small multiples grid based on two variables


```r
ggplot(data = mpg, aes(x = displ, y = hwy)) + 
  geom_point() + 
* facet_grid(drv ~ cyl)
```

&lt;img src="slides-source_files/figure-html/unnamed-chunk-82-1.png" style="display: block; margin: auto;" /&gt;

]
]

---

class: yourturn

# Your Turn!

.pull-left[

### Challenge

1. Compute total spend by store region and week.  Plot the week vs total spend and use facetting to compare store regions.

]

--

.pull-right[

### Solution


```r
transactions %&gt;%
  group_by(store_r, week_num) %&gt;%
  summarize(spend = sum(spend, na.rm = TRUE)) %&gt;%
  ggplot(aes(x = week_num, spend)) +
  geom_line() + 
  facet_wrap(~ store_r)
```

&lt;img src="slides-source_files/figure-html/unnamed-chunk-83-1.png" style="display: block; margin: auto;" /&gt;

]

---

# Titles &amp; Axes

.bold[We can add titles with `ggtitle()` or with `labs()`]

--

.pull-left[


```r
ggplot(data = mpg, aes(x = displ, y = hwy)) + 
  geom_jitter() +
* ggtitle("Displacement vs Highway MPG",
*         subtitle = "Data from 1999 &amp; 2008")
```

&lt;img src="slides-source_files/figure-html/unnamed-chunk-84-1.png" style="display: block; margin: auto;" /&gt;


]

.pull-right[


```r
ggplot(data = mpg, aes(x = displ, y = hwy)) + 
  geom_jitter() +
* labs(
*   title = "Displacement vs Highway MPG",
*   subtitle = "Data from 1999 &amp; 2008",
*   caption = "http://fueleconomy.gov"
*   )
```

&lt;img src="slides-source_files/figure-html/unnamed-chunk-85-1.png" style="display: block; margin: auto;" /&gt;


]

---

# Titles &amp; Axes

.bold[We can add adjust axes with various `scale_xxxx()` functions]

--

.pull-left[


```r
ggplot(data = txhousing, aes(x = volume, y = median)) + 
  geom_point(alpha = .25) +
* scale_x_log10()
```

&lt;img src="slides-source_files/figure-html/unnamed-chunk-86-1.png" style="display: block; margin: auto;" /&gt;


]

.pull-right[


```r
ggplot(data = txhousing, aes(x = volume, y = median)) + 
  geom_point(alpha = .25)  +
* scale_y_continuous(name = "Median Sales Price", labels = scales::dollar) +
* scale_x_log10(name = "Total Sales Volume", labels = scales::comma)
```

&lt;img src="slides-source_files/figure-html/unnamed-chunk-87-1.png" style="display: block; margin: auto;" /&gt;

]

---

# Putting it all together...


```r
ggplot(data = txhousing, aes(x = volume, y = median)) + 
  geom_point(alpha = .15) +
  scale_y_continuous(name = "Median Sales Price", labels = scales::dollar) +
  scale_x_log10(name = "Total Sales Volume", labels = scales::comma) +
  labs(
    title = "Texas Housing Sales",
    subtitle = "Sales data from 2000-2010 provided by the TAMU real estate center",
    caption = " http://recenter.tamu.edu/"
    )
```

&lt;img src="slides-source_files/figure-html/unnamed-chunk-88-1.png" style="display: block; margin: auto;" /&gt;

---
class: yourturn

# Your Turn!
    </textarea>
<script src="libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
